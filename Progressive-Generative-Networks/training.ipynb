{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!git clone https://github.com/crashmoon/Progressive-Generative-Networks.git!pip install plot\n",
        "\n",
        "!pip install pynvml\n",
        "\n",
        "!pip install pytorch_ssim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "dosXZzY35Jsw"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import CelebA\n",
        "import pynvml\n",
        "import pytorch_ssim\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage import io, transform\n",
        "import csv\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from __future__ import print_function, division\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "import plot\n",
        "\n",
        "import scipy.misc\n",
        "import imageio\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.autograd as autograd\n",
        "\n",
        "from os.path import join\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import os\n",
        "from skimage import io, transform\n",
        "from skimage.transform import resize\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "tJ24-8PsAS2S"
      },
      "outputs": [],
      "source": [
        "\n",
        "pynvml.nvmlInit()\n",
        "\n",
        "# Get handle for GPU 0\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "\n",
        "# Get power usage\n",
        "power_usage = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # convert to watts\n",
        "\n",
        "# Get GPU utilization\n",
        "utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
        "gpu_utilization = utilization.gpu\n",
        "\n",
        "# Get fan speed\n",
        "#fan_speed = pynvml.nvmlDeviceGetFanSpeed(handle)\n",
        "\n",
        "# Get temperature\n",
        "temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHf5B6WJ5rEI",
        "outputId": "49d62397-529f-416d-de3b-504c0e595fa3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1443490838it [00:45, 31688466.40it/s]\n",
            "26721026it [00:00, 105955982.72it/s]\n",
            "3424458it [00:00, 239187641.75it/s]\n",
            "6082035it [00:00, 99225963.49it/s]\n",
            "12156055it [00:00, 112863730.18it/s]\n",
            "2836386it [00:00, 167095034.14it/s]\n"
          ]
        }
      ],
      "source": [
        "dataset = CelebA('/content', download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xi5qsg3200s",
        "outputId": "742f806e-1579-4683-8c72-40bed7150e38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "202599\n"
          ]
        }
      ],
      "source": [
        "\n",
        "os.chdir('/content/celeba/img_align_celeba/')\n",
        "name = os.listdir(os.getcwd())\n",
        "\n",
        "id = 0\n",
        "with open('/content/Progressive-Generative-Networks/gan_lstm.csv','w') as csvfile:    \n",
        "    w = csv.writer(csvfile)\n",
        "    w.writerow([0, 1])\n",
        "    for x in name:\n",
        "        w.writerow(['/content/celeba/img_align_celeba/'+x, id])\n",
        "        id+=1\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Param:\n",
        "    unet_channel = 64\n",
        "    cnn_channel = 64\n",
        "    batch_size = 16\n",
        "    image_size = 128\n",
        "    n_critic = 1\n",
        "    gan_weight = 0.001\n",
        "    tv_weight = 1.0\n",
        "    weight_decay = 0.00\n",
        "    G_learning_rate = 0.0002\n",
        "    D_learning_rate = 0.00002\n",
        "    out_path = '/content/output_a100/'\n",
        "\n",
        "\n",
        "def conv_down(dim_in, dim_out):\n",
        "    \"\"\"\n",
        "    Applies a downsampling convolution operation to an input tensor.\n",
        "\n",
        "    Args:\n",
        "        dim_in (int): Number of input channels.\n",
        "        dim_out (int): Number of output channels.\n",
        "\n",
        "    Returns:\n",
        "        nn.Sequential: A sequence of convolutional layers that performs the\n",
        "        downsampling operation.\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(dim_in, dim_out, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(dim_out)\n",
        "    )\n",
        "\n",
        "\n",
        "def conv_up(dim_in, dim_out):\n",
        "    \"\"\"\n",
        "    Applies an upsampling convolution operation to an input tensor.\n",
        "\n",
        "    Args:\n",
        "        dim_in (int): Number of input channels.\n",
        "        dim_out (int): Number of output channels.\n",
        "\n",
        "    Returns:\n",
        "        nn.Sequential: A sequence of convolutional layers that performs the\n",
        "        upsampling operation.\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(dim_in, dim_out, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(dim_out)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Unet(nn.Module):\n",
        "    \"\"\"\n",
        "    A class representing a U-Net architecture for image segmentation.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    unet_input_channel : int\n",
        "        Number of input channels for the U-Net architecture.\n",
        "    hidden_channel : int\n",
        "        Number of channels in the hidden layers of the U-Net architecture.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    forward(data_in, hidden_input=None)\n",
        "        Computes forward pass of the U-Net architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self, unet_input_channel=3, hidden_channel=Param.unet_channel * 8):\n",
        "        \"\"\"\n",
        "        Initializes the U-Net architecture.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        unet_input_channel : int, optional\n",
        "            Number of input channels for the U-Net architecture (default is 3).\n",
        "        hidden_channel : int, optional\n",
        "            Number of channels in the hidden layers of the U-Net architecture (default is 8 times the unet_channel parameter).\n",
        "        \"\"\"\n",
        "        super(Unet, self).__init__()\n",
        "        self.start = nn.Conv2d(unet_input_channel, Param.unet_channel,3,1,1)  # 128\n",
        "        self.conv0 = conv_down(Param.unet_channel, Param.unet_channel)  # 64\n",
        "        self.conv1 = conv_down(Param.unet_channel, Param.unet_channel * 2)  # 32\n",
        "        self.conv2 = conv_down(Param.unet_channel * 2, Param.unet_channel * 4)  # 16\n",
        "        self.conv3 = conv_down(Param.unet_channel * 4, Param.unet_channel * 8)  # 8\n",
        "        self.conv4 = conv_down(Param.unet_channel * 8, Param.unet_channel * 8)  # 4\n",
        "        self.conv5 = conv_down(Param.unet_channel * 8, Param.unet_channel * 8)  # 2\n",
        "        self.conv6 = conv_down(Param.unet_channel * 8, Param.unet_channel * 8)  # 1\n",
        "\n",
        "        self.up5 = conv_up(hidden_channel, Param.unet_channel * 8)  # 2\n",
        "        self.dp5 = nn.Dropout(p=0.5)\n",
        "        self.up4 = conv_up(Param.unet_channel * 8 * 2, Param.unet_channel * 8)  # 4\n",
        "        self.dp4 = nn.Dropout(p=0.5)\n",
        "        self.up3 = conv_up(Param.unet_channel * 8 * 2, Param.unet_channel * 8)  # 8\n",
        "        self.dp3 = nn.Dropout(p=0.5)\n",
        "        self.up2 = conv_up(Param.unet_channel * 8 * 2, Param.unet_channel * 4)  # 16\n",
        "        self.up1 = conv_up(Param.unet_channel * 4 * 2, Param.unet_channel * 2)  # 32\n",
        "        self.up0 = conv_up(Param.unet_channel * 2 * 2, Param.unet_channel)  # 64\n",
        "        self.end = conv_up(Param.unet_channel * 2, 3)  # 128\n",
        "\n",
        "        ## weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                nn.init.kaiming_normal(m.weight.data, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, data_in, hidden_input=None):\n",
        "        \"\"\"\n",
        "        Perform the forward pass of the MyModel.\n",
        "\n",
        "        Args:\n",
        "            data_in (torch.Tensor): Input tensor of shape (batch_size, num_channels, height, width).\n",
        "            hidden_input (torch.Tensor): Hidden input tensor of shape (batch_size, num_channels, 1, 1).\n",
        "                If None, the hidden input will be skipped.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple of two tensors. The first tensor is the output tensor of shape\n",
        "            (batch_size, num_channels, height, width). The second tensor is the mid tensor of shape\n",
        "            (batch_size, num_channels, 1, 1).\n",
        "        \"\"\"\n",
        "        start_out = self.start(data_in)\n",
        "        conv0_out = self.conv0(start_out)\n",
        "        conv1_out = self.conv1(conv0_out)\n",
        "        conv2_out = self.conv2(conv1_out)\n",
        "        conv3_out = self.conv3(conv2_out)\n",
        "        conv4_out = self.conv4(conv3_out)\n",
        "        conv5_out = self.conv5(conv4_out)\n",
        "        conv6_out = self.conv6(conv5_out)\n",
        "\n",
        "        mid = conv6_out  # Param.batch_size * 256 * 1 * 1\n",
        "\n",
        "        if hidden_input is None:\n",
        "            up5_out = self.up5(conv6_out)\n",
        "        else:\n",
        "            hidden_input = hidden_input.view(hidden_input.size(0), hidden_input.size(1), 1, 1)\n",
        "            up5_out = self.up5(torch.cat((hidden_input, conv6_out), 1))\n",
        "\n",
        "        up4_out = self.up4(torch.cat((up5_out, conv5_out), 1))\n",
        "        up3_out = self.up3(torch.cat((up4_out, conv4_out), 1))\n",
        "        up2_out = self.up2(torch.cat((up3_out, conv3_out), 1))\n",
        "        up1_out = self.up1(torch.cat((up2_out, conv2_out), 1))\n",
        "        up0_out = self.up0(torch.cat((up1_out, conv1_out), 1))\n",
        "        out = self.end(torch.cat((up0_out, conv0_out), 1))\n",
        "        out = F.sigmoid(out)\n",
        "        return out, mid\n",
        "\n",
        "def conv_stage(dim_in, dim_out):\n",
        "    \"\"\"\n",
        "    Create a convolutional stage.\n",
        "\n",
        "    Args:\n",
        "        dim_in (int): Number of input channels.\n",
        "        dim_out (int): Number of output channels.\n",
        "\n",
        "    Returns:\n",
        "        nn.Sequential: A sequential container of convolutional layers.\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(dim_in, dim_out, 4, 2, 1,bias=False),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.BatchNorm2d(dim_out)\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"\n",
        "    A class representing the Convolutional Neural Network (CNN) used in the project.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    conv0 : torch.nn.Conv2d\n",
        "        The first convolutional layer of the network.\n",
        "    conv1 : torch.nn.Sequential\n",
        "        The second stage of the network, consisting of two convolutional layers and a batch normalization layer.\n",
        "    conv2 : torch.nn.Sequential\n",
        "        The third stage of the network, consisting of two convolutional layers and a batch normalization layer.\n",
        "    conv3 : torch.nn.Conv2d\n",
        "        The final convolutional layer of the network.\n",
        "    bn0 : torch.nn.BatchNorm2d\n",
        "        A batch normalization layer applied after the first convolutional layer.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    forward(data_in: torch.Tensor) -> torch.Tensor:\n",
        "        Performs a forward pass of the network on the input tensor.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(3, Param.cnn_channel, 3, 1, 1,bias=False)\n",
        "        self.conv1 = conv_stage(Param.cnn_channel, Param.cnn_channel * 2)\n",
        "        self.conv2 = conv_stage(Param.cnn_channel * 2, Param.cnn_channel * 4)\n",
        "        self.conv3 = nn.Conv2d(Param.cnn_channel * 4, 1, 4, 1, 1)\n",
        "        self.bn0 = nn.BatchNorm2d(Param.cnn_channel)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                nn.init.kaiming_normal(m.weight.data, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, data_in):\n",
        "        \"\"\"\n",
        "        Performs a forward pass of the network on the input tensor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data_in : torch.Tensor\n",
        "            The input tensor to be processed by the network. Should have shape [batch_size, 3, height, width].\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The output tensor of the network. Should have shape [batch_size, 1, height, width].\n",
        "        \"\"\"\n",
        "          # map   channel\n",
        "        conv0_out = self.conv0(data_in)  # 128   64\n",
        "        conv0_out = self.bn0(conv0_out)\n",
        "        conv1_out = self.conv1(conv0_out)  # 64    128\n",
        "        conv2_out = self.conv2(conv1_out)  # 32    256\n",
        "        out = self.conv3(conv2_out)  # 31    1\n",
        "        out = F.sigmoid(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class ParisData(object):\n",
        "    def __init__(self, csv_file, trans=None):\n",
        "        self.lines = pd.read_csv(csv_file)\n",
        "        self.trans = trans\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lines)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # print(self.lines)\n",
        "        image_pos = self.lines.loc[idx, '0']\n",
        "        image = io.imread(image_pos)\n",
        "        image = image.astype(np.float)\n",
        "        h,w = image.shape[:2]\n",
        "        if(h<w):\n",
        "            factor = h/350.0\n",
        "            w = w/factor\n",
        "            h = 350\n",
        "        else:\n",
        "            factor = w/350.0\n",
        "            h = h/factor\n",
        "            w = 350\n",
        "        image = transform.resize(image, (int(h), int(w), 3))\n",
        "        image_id = self.lines.loc[idx, '1']\n",
        "        sample = {'image': image, 'id': image_id}\n",
        "        if self.trans is not None:\n",
        "            sample = self.trans(sample)\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RandCrop(object):\n",
        "    def __call__(self, sample):\n",
        "        image = sample['image']\n",
        "        image_id = sample['id']\n",
        "        h, w = image.shape[:2]\n",
        "        sx = random.randint(0, h - Param.image_size)\n",
        "        sy = random.randint(0, w - Param.image_size)\n",
        "        image = image[sx:(sx + Param.image_size), sy:(sy + Param.image_size)]\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        if(random.randint(0,1)):\n",
        "            image = image[:,:,::-1]\n",
        "        image /= 255.0\n",
        "        image_trans = np.array(image)\n",
        "        return {'image': torch.FloatTensor(image_trans), 'id': torch.Tensor([image_id])}\n",
        "\n",
        "    def inf_get(train):\n",
        "        while (True):\n",
        "            for x in train:\n",
        "                yield x['image']\n",
        "\n",
        "    def destroy(image, crop_size=64):\n",
        "        re = image.clone().cuda()\n",
        "        '''\n",
        "        re[:, :, int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size),\n",
        "        int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size)] = torch.zeros(\n",
        "            Param.batch_size, 3, crop_size, crop_size).cuda()\n",
        "        '''\n",
        "        re[:, 0:1, int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size),\n",
        "        int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size)] = torch.zeros(\n",
        "            Param.batch_size, 1, crop_size, crop_size).fill_(0.45703125).cuda()\n",
        "        re[:, 1:2, int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size),\n",
        "        int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size)] = torch.zeros(\n",
        "            Param.batch_size, 1, crop_size, crop_size).fill_(0.40625).cuda()\n",
        "        re[:, 2:3, int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size),\n",
        "        int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size)] = torch.zeros(\n",
        "            Param.batch_size, 1, crop_size, crop_size).fill_(0.48046875).cuda()\n",
        "\n",
        "        return re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class Net_G(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    Generator network for image translation using LSTM-based U-Net architecture.\n",
        "\n",
        "    Args:\n",
        "        None\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Net_G, self).__init__()\n",
        "        self.unet_1 = Unet(3, Param.unet_channel * 8)\n",
        "        self.unet_2 = Unet(6, Param.unet_channel * 8 * 3)\n",
        "        self.unet_3 = Unet(6, Param.unet_channel * 8 * 3)\n",
        "        self.unet_4 = Unet(6, Param.unet_channel * 8 * 3)\n",
        "        self.rnn = nn.LSTMCell(Param.unet_channel * 8, Param.unet_channel * 8 * 2)\n",
        "\n",
        "    def forward(self, data_1, data_2, data_3, data_4, h0, c0):\n",
        "       \"\"\"\n",
        "        Forward pass for the generator network.\n",
        "\n",
        "        Args:\n",
        "            data_1 (torch.Tensor): Input image tensor.\n",
        "            data_2 (torch.Tensor): Second input image tensor.\n",
        "            data_3 (torch.Tensor): Third input image tensor.\n",
        "            data_4 (torch.Tensor): Fourth input image tensor.\n",
        "            h0 (torch.Tensor): Hidden state tensor for LSTM.\n",
        "            c0 (torch.Tensor): Cell state tensor for LSTM.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of output tensors from each of the four U-Nets.\n",
        "        \"\"\"\n",
        "        #print(data_1.size())\n",
        "        unet_out_1, unet_mid_1 = self.unet_1(data_1)\n",
        "        h1, c1 = self.rnn(unet_mid_1.view(Param.batch_size, -1), (h0, c0))\n",
        "        unet_out_2, unet_mid_2 = self.unet_2(torch.cat((data_1, unet_out_1), 1), h1)\n",
        "        h2, c2 = self.rnn(unet_mid_2.view(Param.batch_size, -1), (h1, c1))\n",
        "        unet_out_3, unet_mid_3 = self.unet_3(torch.cat((data_1, unet_out_2), 1), h2)\n",
        "        h3, c3 = self.rnn(unet_mid_3.view(Param.batch_size, -1), (h2, c2))\n",
        "        unet_out_4, unet_mid_4 = self.unet_4(torch.cat((data_1, unet_out_3), 1), h3)\n",
        "        return unet_out_1, unet_out_2, unet_out_3, unet_out_4\n",
        "\n",
        "\n",
        "class Net_D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_D, self).__init__()\n",
        "        self.cnn1 = CNN()\n",
        "        self.cnn2 = CNN()\n",
        "        self.cnn3 = CNN()\n",
        "        self.cnn4 = CNN()\n",
        "\n",
        "    def forward(self, data_48, data_32, data_16, data_0):\n",
        "        out1 = self.cnn1(data_48)\n",
        "        out2 = self.cnn2(data_32)\n",
        "        out3 = self.cnn3(data_16)\n",
        "        out4 = self.cnn4(data_0)\n",
        "        return out1, out2, out3, out4\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define some helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "BBP1WKHo7F3c"
      },
      "outputs": [],
      "source": [
        "\n",
        "def save_image_plus(x, save_path):\n",
        "    x = (255.99 * x).astype('uint8')\n",
        "    x = x.transpose(0, 1, 3, 4, 2)\n",
        "    nh, nw = x.shape[:2]\n",
        "    h = x.shape[2]\n",
        "    w = x.shape[3]\n",
        "    img = np.zeros((h * nh, w * nw, 3))\n",
        "    for i in range(nh):\n",
        "        for j in range(nw):\n",
        "            img[i * h:i * h + h, j * w:j * w + w] = x[i][j]\n",
        "    imageio.imwrite(save_path, img)\n",
        "    # imsave(save_path, img)\n",
        "\n",
        "def cal_tv(image):\n",
        "    temp = image.clone()\n",
        "    temp[:,:,:Param.image_size-1,:] = image[:,:,1:,:]\n",
        "    re = ((image-temp)**2).mean()\n",
        "    temp = image.clone()\n",
        "    temp[:,:,:,:Param.image_size-1] = image[:,:,:,1:]\n",
        "    re += ((image-temp)**2).mean()\n",
        "    return re\n",
        "\n",
        "def ssim_fn(y_true, y_pred):\n",
        "    ssim_val = 0\n",
        "    for i in range(y_true.shape[0]):\n",
        "        true_img = y_true[i, :, :, :]\n",
        "        pred_img = y_pred[i, :, :, :]\n",
        "        true_img = cv2.cvtColor(true_img.permute(1,2,0).detach().cpu().numpy(), cv2.COLOR_RGB2GRAY)\n",
        "        pred_img = cv2.cvtColor(pred_img.permute(1,2,0).detach().cpu().numpy(), cv2.COLOR_RGB2GRAY)\n",
        "        ssim_val += ssim(true_img, pred_img, data_range=255)\n",
        "    return ssim_val / y_true.shape[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code initializes various variables and sets up the training process for a Generative Adversarial Network (GAN) with a Long Short-Term Memory (LSTM) module. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8v8EZWnpC33",
        "outputId": "89b84d57-f72c-4dcf-cb4b-7ff5564eaea8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-89-6d3113006b5e>:90: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data, mode='fan_out')\n",
            "<ipython-input-89-6d3113006b5e>:145: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data, mode='fan_out')\n"
          ]
        }
      ],
      "source": [
        "# one = torch.FloatTensor([1.0]).cuda() //deprecateed\n",
        "scaler = amp.GradScaler()\n",
        "one = torch.tensor(1.0, dtype=torch.float).cuda()\n",
        "mone = torch.tensor(-1.0, dtype=torch.float).cuda()\n",
        "# mone = torch.FloatTensor([-1.0]).cuda()\n",
        "ones_31 = torch.zeros(Param.batch_size, 1, 31, 31).fill_(1.0).type(torch.FloatTensor).cuda()\n",
        "mones_31 = torch.zeros(Param.batch_size, 1, 31, 31).fill_(-1.0).type(torch.FloatTensor).cuda()\n",
        "zeros_31 = torch.zeros(Param.batch_size, 1, 31, 31).type(torch.FloatTensor).cuda()\n",
        "\n",
        "mask = torch.ones(Param.batch_size, 3, 128, 128)\n",
        "mask[:, :, 32:32 + 64, 32:32 + 64] = torch.zeros(Param.batch_size, 3, 64, 64)\n",
        "mask = Variable(mask.type(torch.FloatTensor).cuda(), requires_grad=False)\n",
        "\n",
        "h0 = torch.zeros(Param.batch_size, Param.unet_channel * 8 * 2).cuda()\n",
        "c0 = torch.zeros(Param.batch_size, Param.unet_channel * 8 * 2).cuda()\n",
        "\n",
        "netG = Net_G().cuda()\n",
        "netD = Net_D().cuda()\n",
        "\n",
        "#netG.load_state_dict(torch.load('/data/haoran/unet-gan/gan_lstm_4/netG_59999.pickle'))\n",
        "#netD.load_state_dict(torch.load('/data/haoran/unet-gan/gan_lstm_4/netD_59999.pickle'))\n",
        "#netG = nn.DataParallel(netG, device_ids=[0, 1])\n",
        "#netD = nn.DataParallel(netD, device_ids=[0, 1])\n",
        "\n",
        "opt_G = optim.Adam(netG.parameters(), lr=Param.G_learning_rate, betas = (0.5,0.999), weight_decay=Param.weight_decay)\n",
        "opt_D = optim.Adam(netD.parameters(), lr=Param.D_learning_rate, betas = (0.5,0.999), weight_decay=Param.weight_decay)\n",
        "\n",
        "#trainset = ParisData('paris.csv', RandCrop())\n",
        "trainset = ParisData('/content/Progressive-Generative-Networks/gan_lstm.csv', RandCrop())\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=Param.batch_size, shuffle=True, num_workers=2,\n",
        "                                            drop_last=True)\n",
        "train_data = inf_get(train_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "qSoWOhP1plBi"
      },
      "outputs": [],
      "source": [
        "epoch_start = 0\n",
        "maxepoch = 10\n",
        "bce_loss = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "UzcdaXwwSZL7"
      },
      "outputs": [],
      "source": [
        "def get_memory_bandwidth(data_size_bytes, time_sec):\n",
        "    return data_size_bytes / time_sec / 1e9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "ezUJ8oe8SbJO"
      },
      "outputs": [],
      "source": [
        "def get_num_flops(model, input_shape):\n",
        "    inputs = torch.randn(*input_shape)\n",
        "    flops, _ = torch.autograd.profiler.profile(lambda: model(inputs), verbose=False)\n",
        "    return flops / 1e9"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training a GAN (Generative Adversarial Network). The GAN has two components: a generator network (netG) and a discriminator network (netD). The generator network creates fake images, and the discriminator network determines whether an image is real or fake. The two networks are trained in a loop, with the generator network attempting to produce increasingly convincing fake images while the discriminator network tries to correctly classify the images as real or fake.\n",
        "\n",
        "The training process itself is divided into two steps, corresponding to training the discriminator and the generator networks, respectively. Each step involves a forward and backward pass through the network, with gradients computed and used to update the network parameters via an optimizer (opt_D or opt_G). The loss function used is a combination of a binary cross-entropy loss (bce_loss), an L1 loss (l1_loss), and a total variation (tv) loss.\n",
        "\n",
        "The code also includes some profiling functionality, using the PyNVML library to track GPU utilization, temperature, and power usage. The training progress is output to the console at each epoch, including the D cost, G cost, and L1 loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "EJMXO28G9CEO"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train_runner(epoch, maxepoch, bce_loss,val):\n",
        "    # run the model with profiling\n",
        "    \n",
        "    while (epoch < maxepoch):\n",
        "        start_time = time.time()\n",
        "        # step D\n",
        "        for p in netD.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        real_data = next(train_data)\n",
        "        # print(real_data)\n",
        "        real_data = real_data.cuda()\n",
        "        real_data_64 = destroy(real_data, 64)\n",
        "        real_data_48 = destroy(real_data, 48)\n",
        "        real_data_32 = destroy(real_data, 32)\n",
        "        real_data_16 = destroy(real_data, 16)\n",
        "\n",
        "        real_data_64 = Variable(real_data_64)\n",
        "        real_data_48 = Variable(real_data_48)\n",
        "        real_data_32 = Variable(real_data_32)\n",
        "        real_data_16 = Variable(real_data_16)\n",
        "        real_data_0 = Variable(real_data)\n",
        "\n",
        "        netD.zero_grad()\n",
        "        with amp.autocast():\n",
        "            p_real_48, p_real_32, p_real_16, p_real_0 = netD(real_data_48, real_data_32, real_data_16, real_data_0)\n",
        "            target = Variable(ones_31)\n",
        "\n",
        "            #print(p_real_48.size())\n",
        "            real_loss_48 = bce_loss(p_real_48, target)\n",
        "            real_loss_32 = bce_loss(p_real_32, target)\n",
        "            real_loss_16 = bce_loss(p_real_16, target)\n",
        "            real_loss_0 = bce_loss(p_real_0, target)\n",
        "\n",
        "            fake_data_48, fake_data_32, fake_data_16, fake_data_0 = netG(real_data_64, real_data_48, real_data_32,\n",
        "                                                                            real_data_16, Variable(h0), Variable(c0))\n",
        "\n",
        "            p_fake_48, p_fake_32, p_fake_16, p_fake_0 = netD(Variable(fake_data_48.data), Variable(fake_data_32.data), Variable(fake_data_16.data), Variable(fake_data_0.data))\n",
        "            target = Variable(zeros_31)\n",
        "            fake_loss_48 = bce_loss(p_fake_48, target)\n",
        "            fake_loss_32 = bce_loss(p_fake_32, target)\n",
        "            fake_loss_16 = bce_loss(p_fake_16, target)\n",
        "            fake_loss_0 = bce_loss(p_fake_0, target)\n",
        "\n",
        "            gan_loss = real_loss_48 + real_loss_32 + real_loss_16 + real_loss_0 + fake_loss_48 + fake_loss_32 + fake_loss_16 + fake_loss_0\n",
        "            gan_loss = gan_loss\n",
        "\n",
        "\n",
        "            l1_loss = ((fake_data_48 - real_data_48).abs()).mean() + ((fake_data_32 - real_data_32).abs()).mean() + ((\n",
        "                fake_data_16 - real_data_16).abs()).mean() + ((fake_data_0 - real_data_0).abs()).mean()\n",
        "\n",
        "            tv_loss = cal_tv(fake_data_48) + cal_tv(fake_data_32) + cal_tv(fake_data_16) + cal_tv(fake_data_0)\n",
        "            tv_loss = tv_loss * Param.tv_weight\n",
        "        #gan_loss.backward()\n",
        "        scaler.scale(gan_loss).backward(retain_graph=True)\n",
        "        scaler.step(opt_D)\n",
        "        scaler.update()        \n",
        "\n",
        "        # D_cost = fake_loss_48.data + fake_loss_32.data + fake_loss_16.data + fake_loss_0.data\n",
        "        # D_cost += real_loss_48.data + real_loss_32.data + real_loss_16.data + real_loss_0.data\n",
        "\n",
        "        #opt_D.step()\n",
        "\n",
        "        ##################\n",
        "        ## step G ########\n",
        "        ##################\n",
        "        for p in netD.parameters():\n",
        "            p.requires_grad = False\n",
        "        netG.zero_grad()\n",
        "\n",
        "\n",
        "        with amp.autocast():\n",
        "            p_fake_48, p_fake_32, p_fake_16, p_fake_0 = netD(fake_data_48, fake_data_32, fake_data_16, fake_data_0)\n",
        "            #target = Variable(ones_31)\n",
        "            target = Variable(zeros_31)\n",
        "            fake_loss_48 = bce_loss(p_fake_48, target)\n",
        "            fake_loss_32 = bce_loss(p_fake_32, target)\n",
        "            fake_loss_16 = bce_loss(p_fake_16, target)\n",
        "            fake_loss_0 = bce_loss(p_fake_0, target)\n",
        "\n",
        "            gan_loss = fake_loss_48 + fake_loss_32 + fake_loss_16 + fake_loss_0\n",
        "            gan_loss = - gan_loss * Param.gan_weight\n",
        "\n",
        "\n",
        "        scaler.scale(gan_loss).backward(retain_graph=True)\n",
        "        scaler.scale(l1_loss).backward(retain_graph=True)\n",
        "        scaler.scale(tv_loss).backward(retain_graph=True)\n",
        "        scaler.step(opt_G)\n",
        "        scaler.update()   \n",
        "        # gan_loss.backward(retain_graph=True)\n",
        "        # l1_loss.backward(one, retain_graph=True)\n",
        "        # tv_loss.backward(one, retain_graph=True)\n",
        "\n",
        "        # G_cost = fake_loss_48.data + fake_loss_32.data + fake_loss_16.data + fake_loss_0.data\n",
        "        # G_cost += l1_loss.data\n",
        "        # opt_G.step()\n",
        "        print('Epoch:', epoch, 'L1 Loss:', l1_loss.data)\n",
        "\n",
        "        os.chdir(Param.out_path)\n",
        "        # print('Train D Cost:', D_cost)\n",
        "        print('Time Elapsed:', time.time() - start_time)\n",
        "        # print('Train G Cost:', G_cost)\n",
        "        print('Train L1 Loss:', l1_loss.data.cpu().numpy())\n",
        "\n",
        "        times.append(time.time() - start_time)\n",
        "        \n",
        "\n",
        "        power_usage = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # convert to watts\n",
        "        utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
        "        gpu_utilization = utilization.gpu\n",
        "        temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)\n",
        "        power_list.append(power_usage)\n",
        "        gpu_list.append(gpu_utilization)\n",
        "        #fan_list.append(fan_speed)\n",
        "        temp_list.append(temperature)\n",
        "        loss_list.append(l1_loss.data.cpu().numpy())\n",
        "        mse = torch.mean((fake_data_0.data - real_data_0.data) ** 2)\n",
        "        print('mse: '+str(mse))\n",
        "        # psnr = 20 * torch.log10(1 / torch.sqrt(mse))\n",
        "        # psnr_list.append(psnr.item())\n",
        "        # ssim=ssim_fn(fake_data_0,real_data_0)\n",
        "        # ssim_list.append(ssim)\n",
        "\n",
        "        if epoch % 100 == 99:\n",
        "            out_image = torch.cat(\n",
        "                (\n",
        "                    fake_data_48.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    fake_data_32.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    fake_data_16.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    fake_data_0.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    real_data_64.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    real_data_48.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    real_data_32.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    real_data_16.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    real_data_0.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size)\n",
        "                ),\n",
        "                1\n",
        "            )\n",
        "            save_image_plus(out_image.cpu().numpy(), Param.out_path + 'train_image_{}.jpg'.format(epoch))\n",
        "\n",
        "        if epoch % 100 == 99:\n",
        "            torch.save(netD.state_dict(),Param.out_path+ 'netD_{}.pickle'.format(epoch))\n",
        "            torch.save(netG.state_dict(),Param.out_path+ 'netG_{}.pickle'.format(epoch))\n",
        "        diff=l1_loss.data.cpu().numpy()-val\n",
        "        if(diff<0.0004):\n",
        "          print(\"testing\")\n",
        "          print(diff)\n",
        "          print(l1_loss.data.cpu().numpy())\n",
        "          print(epoch)\n",
        "          break\n",
        "            \n",
        "        epoch += 1\n",
        "          \n",
        "    \n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "FaErYAfWf-Tn"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/output_V100_mp/V100_lists.pkl','rb') as f:\n",
        "  lists=pickle.load(f)\n",
        "val=lists[7][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1z0MpjtF8nF",
        "outputId": "07202177-ac27-4bfd-abaf-37a45575aec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.31375197\n"
          ]
        }
      ],
      "source": [
        "print(val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run for 200 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTlKpxjKpiSd",
        "outputId": "773c4b28-d5eb-4915-baaf-9bf81e936c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 L1 Loss: tensor(0.3980, device='cuda:0')\n",
            "Time Elapsed: 0.22330594062805176\n",
            "Train L1 Loss: 0.3979774\n",
            "mse: tensor(0.0208, device='cuda:0')\n",
            "Epoch: 1 L1 Loss: tensor(0.3134, device='cuda:0')\n",
            "Time Elapsed: 0.24210309982299805\n",
            "Train L1 Loss: 0.31340593\n",
            "mse: tensor(0.0131, device='cuda:0')\n",
            "testing\n",
            "-0.00034603477\n",
            "0.31340593\n",
            "1\n",
            "warmup\n",
            "Epoch: 0 L1 Loss: tensor(0.3436, device='cuda:0')\n",
            "Time Elapsed: 0.32890963554382324\n",
            "Train L1 Loss: 0.34362915\n",
            "mse: tensor(0.0158, device='cuda:0')\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.97%       2.745ms        21.17%      59.772ms     262.158us       0.000us         0.00%      82.020ms     359.737us           0 b           0 b       1.28 Gb      -1.42 Gb           228  \n",
            "                                   ConvolutionBackward0         0.74%       2.091ms        20.05%      56.621ms     248.338us       0.000us         0.00%      81.950ms     359.430us           0 b           0 b       2.70 Gb           0 b           228  \n",
            "                             aten::convolution_backward        10.92%      30.849ms        19.31%      54.530ms     239.167us      81.186ms        45.27%      81.950ms     359.430us           0 b           0 b       2.70 Gb       1.61 Gb           228  \n",
            "                                       cudaLaunchKernel        15.15%      42.782ms        15.15%      42.782ms       9.220us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          4640  \n",
            "                                               aten::to         3.16%       8.923ms        12.70%      35.866ms      51.384us       0.000us         0.00%       9.341ms      13.383us         908 b          12 b       2.76 Gb      70.01 Mb           698  \n",
            "autograd::engine::evaluate_function: CudnnBatchNormB...         0.86%       2.438ms        11.86%      33.484ms     164.137us       0.000us         0.00%      16.034ms      78.598us           0 b           0 b     190.25 Mb    -874.91 Mb           204  \n",
            "                                CudnnBatchNormBackward0         0.85%       2.413ms        10.84%      30.614ms     150.069us       0.000us         0.00%      15.962ms      78.245us           0 b           0 b       1.04 Gb    -211.31 Mb           204  \n",
            "                                         aten::_to_copy         3.70%      10.440ms         9.84%      27.793ms      42.497us       0.000us         0.00%       9.598ms      14.676us         908 b          32 b       2.76 Gb           0 b           654  \n",
            "                                           aten::conv2d         0.39%       1.107ms         9.22%      26.031ms     179.524us       0.000us         0.00%      29.860ms     205.931us           0 b           0 b       1.62 Gb     -10.00 Kb           145  \n",
            "                               Optimizer.step#Adam.step         2.64%       7.460ms         7.19%      20.303ms      10.152ms       0.000us         0.00%      20.460ms      10.230ms           0 b           0 b           0 b      -1.50 Gb             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 282.403ms\n",
            "Self CUDA time total: 179.330ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             aten::convolution_backward        10.92%      30.849ms        19.31%      54.530ms     239.167us      81.186ms        45.27%      81.950ms     359.430us           0 b           0 b       2.70 Gb       1.61 Gb           228  \n",
            "void cudnn::ops::nchwToNhwcKernel<__half, __half, fl...         0.00%       0.000us         0.00%       0.000us       0.000us      20.393ms        11.37%      20.393ms      21.834us           0 b           0 b           0 b           0 b           934  \n",
            "                                aten::cudnn_convolution         2.02%       5.703ms         3.13%       8.852ms     110.650us      15.792ms         8.81%      15.792ms     197.400us           0 b           0 b     862.17 Mb     862.17 Mb            80  \n",
            "                        aten::cudnn_batch_norm_backward         3.34%       9.446ms         6.43%      18.152ms      88.980us      15.119ms         8.43%      15.119ms      74.113us           0 b           0 b       1.04 Gb           0 b           204  \n",
            "void cudnn::bn_bw_1C11_kernel_new<__half, float, flo...         0.00%       0.000us         0.00%       0.000us       0.000us      12.539ms         6.99%      12.539ms     208.983us           0 b           0 b           0 b           0 b            60  \n",
            "                                            aten::copy_         2.89%       8.157ms         6.41%      18.107ms      17.597us      10.994ms         6.13%      10.994ms      10.684us           0 b           0 b           0 b           0 b          1029  \n",
            "void cudnn::ops::nhwcToNchwKernel<__half, __half, fl...         0.00%       0.000us         0.00%       0.000us       0.000us       8.786ms         4.90%       8.786ms      20.869us           0 b           0 b           0 b           0 b           421  \n",
            "                                             aten::add_         3.10%       8.754ms         5.57%      15.729ms      19.019us       8.053ms         4.49%       8.053ms       9.738us         528 b        -380 b           0 b           0 b           827  \n",
            "void xmma_cudnn::implicit_gemm::strided_dgrad_indexe...         0.00%       0.000us         0.00%       0.000us       0.000us       8.024ms         4.47%       8.024ms     200.600us           0 b           0 b           0 b           0 b            40  \n",
            "                                 aten::cudnn_batch_norm         2.01%       5.675ms         3.89%      10.975ms     119.293us       7.325ms         4.08%       7.325ms      79.620us           0 b           0 b     803.25 Mb           0 b            92  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 282.403ms\n",
            "Self CUDA time total: 179.330ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#train_runner(epoch_start, 100, torch.nn.functional.binary_cross_entropy_with_logits)\n",
        "power_list=[]\n",
        "temp_list=[]\n",
        "gpu_list=[]\n",
        "fan_list=[]\n",
        "psnr_list=[]\n",
        "ssim_list=[]\n",
        "times = []\n",
        "loss_list=[]\n",
        "train_runner(epoch_start, 200, torch.nn.functional.binary_cross_entropy_with_logits,val)\n",
        "print('warmup')\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True, profile_memory=True) as prof:\n",
        "    train_runner(epoch_start, 1, torch.nn.functional.binary_cross_entropy_with_logits,val)\n",
        "#print(f\"Epoch {0}: {prof.key_averages().memory_bandwidth}\")\n",
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
        "  #analyze the profiling results\n",
        "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "5Jh0OBchhq7W"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K2iLO0hhuls",
        "outputId": "d1f8b5a8-aa5a-4fff-d019-9cbea21b1dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Generator has 199,048,280 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "for p in netG.parameters():\n",
        "    p.requires_grad = True\n",
        "netG.zero_grad()\n",
        "num_params = count_parameters(netG)\n",
        "print(f\"The Generator has {num_params:,} trainable parameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSFjgy0inEdx",
        "outputId": "4d6eccce-8a65-4df9-8fdd-962d93b75ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Generator has 2,648,324 trainable parameters.\n"
          ]
        }
      ],
      "source": [
        "for p in netD.parameters():\n",
        "    p.requires_grad = True\n",
        "netG.zero_grad()\n",
        "num_params = count_parameters(netD)\n",
        "print(f\"The Generator has {num_params:,} trainable parameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rey5esuFnMhq",
        "outputId": "c9a9f0b0-e1c2-435b-b821-50bbdd978707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10607728\n"
          ]
        }
      ],
      "source": [
        "dmem_params = sum([param.nelement()*param.element_size() for param in netD.parameters()])\n",
        "dmem_bufs = sum([buf.nelement()*buf.element_size() for buf in netD.buffers()])\n",
        "dmem = dmem_params + dmem_bufs # in bytes\n",
        "print(dmem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoNwCRgWnRuS",
        "outputId": "b4b5ea59-c02d-4ed8-cd35-7c37a9fd36e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "796337024\n"
          ]
        }
      ],
      "source": [
        "gmem_params = sum([param.nelement()*param.element_size() for param in netG.parameters()])\n",
        "gmem_bufs = sum([buf.nelement()*buf.element_size() for buf in netG.buffers()])\n",
        "gmem = gmem_params + gmem_bufs # in bytes\n",
        "print(gmem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VXZBD-onX1u",
        "outputId": "2d265d1e-5454-49d3-c9aa-927c6f3abe5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "806944752\n"
          ]
        }
      ],
      "source": [
        "mem= dmem + gmem\n",
        "print(mem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgEyr5yjnY3Y",
        "outputId": "fde36f0d-cc2f-4353-b0ef-875f6f7e8501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4413279339081755\n"
          ]
        }
      ],
      "source": [
        "bandwidth=mem/(times[-1] * 1000000000)\n",
        "print(bandwidth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wrFs0oWnh3K",
        "outputId": "e6930df7-44fc-4214-cd59-25a4265b5026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400744884\n"
          ]
        }
      ],
      "source": [
        "flop=2*count_parameters(netG)+count_parameters(netD)\n",
        "print(flop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDn-S0G7nnwi",
        "outputId": "6a235813-5a08-4a78-aa16-57f634944b81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.21241222184687\n"
          ]
        }
      ],
      "source": [
        "flops=flop/(times[-1] * 1000000000)\n",
        "print(flops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "8SPn9nCfoHkD"
      },
      "outputs": [],
      "source": [
        "roofline=[bandwidth,flops]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "q6y_RikqoI7o"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "# Save the lists to a file\n",
        "with open('V100_mp_lists_2.pkl', 'wb') as f:\n",
        "    pickle.dump([power_list, gpu_list, temp_list, psnr_list,ssim_list,times,roofline,loss_list], f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
