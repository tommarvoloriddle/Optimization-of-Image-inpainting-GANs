{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDO5BWVv2zP7",
        "outputId": "30d61b00-d83b-4053-e402-1b686ad1ed5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Progressive-Generative-Networks'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Total 108 (delta 0), reused 0 (delta 0), pack-reused 108\u001b[K\n",
            "Receiving objects: 100% (108/108), 2.46 MiB | 28.29 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/crashmoon/Progressive-Generative-Networks.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plot\n",
        "!pip install pynvml\n",
        "!pip install pytorch_ssim\n",
        "\n"
      ],
      "metadata": {
        "id": "lnrgMc1R_r9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b397d320-db27-40a7-bd53-73d53c434e20"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: plot in /usr/local/lib/python3.10/dist-packages (0.6.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from plot) (3.7.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.10/dist-packages (from plot) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from plot) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from plot) (1.10.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from plot) (6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->plot) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (11.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch_ssim in /usr/local/lib/python3.10/dist-packages (0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "dosXZzY35Jsw"
      },
      "outputs": [],
      "source": [
        "# Import MNIST\n",
        "from torchvision.datasets import CelebA\n",
        "import pynvml\n",
        "import pytorch_ssim\n",
        "from skimage.metrics import structural_similarity as ssim\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pynvml.nvmlInit()\n",
        "\n",
        "# Get handle for GPU 0\n",
        "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "\n",
        "# Get power usage\n",
        "power_usage = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # convert to watts\n",
        "\n",
        "# Get GPU utilization\n",
        "utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
        "gpu_utilization = utilization.gpu\n",
        "\n",
        "# Get fan speed\n",
        "#fan_speed = pynvml.nvmlDeviceGetFanSpeed(handle)\n",
        "\n",
        "# Get temperature\n",
        "temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)"
      ],
      "metadata": {
        "id": "tJ24-8PsAS2S"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHf5B6WJ5rEI",
        "outputId": "49d62397-529f-416d-de3b-504c0e595fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1443490838it [00:45, 31688466.40it/s]\n",
            "26721026it [00:00, 105955982.72it/s]\n",
            "3424458it [00:00, 239187641.75it/s]\n",
            "6082035it [00:00, 99225963.49it/s]\n",
            "12156055it [00:00, 112863730.18it/s]\n",
            "2836386it [00:00, 167095034.14it/s]\n"
          ]
        }
      ],
      "source": [
        "dataset = CelebA('/content', download=True)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xi5qsg3200s",
        "outputId": "742f806e-1579-4683-8c72-40bed7150e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202599\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from skimage import io, transform\n",
        "import csv\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "os.chdir('/content/celeba/img_align_celeba/')\n",
        "name = os.listdir(os.getcwd())\n",
        "print(len(name))\n",
        "# with open('/content/Progressive-Generative-Networks/gan_lstm.csv','w') as csvfile:    \n",
        "#     w = csv.writer(csvfile)\n",
        "#     w.writerow([0, 1])\n",
        "\n",
        "id = 0\n",
        "with open('/content/Progressive-Generative-Networks/gan_lstm.csv','w') as csvfile:    \n",
        "    w = csv.writer(csvfile)\n",
        "    w.writerow([0, 1])\n",
        "    for x in name:\n",
        "        w.writerow(['/content/celeba/img_align_celeba/'+x, id])\n",
        "        id+=1\n",
        "    \n",
        "    \n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install plot"
      ],
      "metadata": {
        "id": "D80Y8cmTiFQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac133b1-2b8c-4729-fb6b-4990ae3152dc"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: plot in /usr/local/lib/python3.10/dist-packages (0.6.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from plot) (3.7.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.10/dist-packages (from plot) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from plot) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from plot) (1.10.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from plot) (6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->plot) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->plot) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "BBP1WKHo7F3c"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "import plot\n",
        "\n",
        "import scipy.misc\n",
        "# from scipy.misc import imsave // deprecated\n",
        "import imageio\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.autograd as autograd\n",
        "\n",
        "from os.path import join\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import os\n",
        "from skimage import io, transform\n",
        "from skimage.transform import resize\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "import cv2\n",
        "from torch.cuda import amp\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "class Param:\n",
        "    unet_channel = 64\n",
        "    cnn_channel = 64\n",
        "    batch_size = 16\n",
        "    image_size = 128\n",
        "    n_critic = 1\n",
        "    gan_weight = 0.001\n",
        "    tv_weight = 1.0\n",
        "    weight_decay = 0.00\n",
        "    G_learning_rate = 0.0002\n",
        "    D_learning_rate = 0.00002\n",
        "    out_path = '/content/output_V100_mp/'\n",
        "\n",
        "\n",
        "def conv_down(dim_in, dim_out):\n",
        "    return nn.Sequential(\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(dim_in, dim_out, kernel_size=4, stride=2, padding=1,bias = False),\n",
        "        nn.BatchNorm2d(dim_out)\n",
        "    )\n",
        "\n",
        "\n",
        "def conv_up(dim_in, dim_out):\n",
        "    return nn.Sequential(\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(dim_in, dim_out, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(dim_out)\n",
        "    )\n",
        "\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, unet_input_channel=3, hidden_channel=Param.unet_channel * 8):\n",
        "        super(Unet, self).__init__()\n",
        "        self.start = nn.Conv2d(unet_input_channel, Param.unet_channel,3,1,1)  # 128\n",
        "        self.conv0 = conv_down(Param.unet_channel, Param.unet_channel)  # 64\n",
        "        self.conv1 = conv_down(Param.unet_channel, Param.unet_channel * 2)  # 32\n",
        "        self.conv2 = conv_down(Param.unet_channel * 2, Param.unet_channel * 4)  # 16\n",
        "        self.conv3 = conv_down(Param.unet_channel * 4, Param.unet_channel * 8)  # 8\n",
        "        self.conv4 = conv_down(Param.unet_channel * 8, Param.unet_channel * 8)  # 4\n",
        "        self.conv5 = conv_down(Param.unet_channel * 8, Param.unet_channel * 8)  # 2\n",
        "        self.conv6 = conv_down(Param.unet_channel * 8, Param.unet_channel * 8)  # 1\n",
        "\n",
        "        self.up5 = conv_up(hidden_channel, Param.unet_channel * 8)  # 2\n",
        "        self.dp5 = nn.Dropout(p=0.5)\n",
        "        self.up4 = conv_up(Param.unet_channel * 8 * 2, Param.unet_channel * 8)  # 4\n",
        "        self.dp4 = nn.Dropout(p=0.5)\n",
        "        self.up3 = conv_up(Param.unet_channel * 8 * 2, Param.unet_channel * 8)  # 8\n",
        "        self.dp3 = nn.Dropout(p=0.5)\n",
        "        self.up2 = conv_up(Param.unet_channel * 8 * 2, Param.unet_channel * 4)  # 16\n",
        "        self.up1 = conv_up(Param.unet_channel * 4 * 2, Param.unet_channel * 2)  # 32\n",
        "        self.up0 = conv_up(Param.unet_channel * 2 * 2, Param.unet_channel)  # 64\n",
        "        self.end = conv_up(Param.unet_channel * 2, 3)  # 128\n",
        "\n",
        "        ## weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                nn.init.kaiming_normal(m.weight.data, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, data_in, hidden_input=None):\n",
        "        start_out = self.start(data_in)\n",
        "        conv0_out = self.conv0(start_out)\n",
        "        conv1_out = self.conv1(conv0_out)\n",
        "        conv2_out = self.conv2(conv1_out)\n",
        "        conv3_out = self.conv3(conv2_out)\n",
        "        conv4_out = self.conv4(conv3_out)\n",
        "        conv5_out = self.conv5(conv4_out)\n",
        "        conv6_out = self.conv6(conv5_out)\n",
        "\n",
        "        mid = conv6_out  # Param.batch_size * 256 * 1 * 1\n",
        "\n",
        "        if hidden_input is None:\n",
        "            up5_out = self.up5(conv6_out)\n",
        "        else:\n",
        "            hidden_input = hidden_input.view(hidden_input.size(0), hidden_input.size(1), 1, 1)\n",
        "            up5_out = self.up5(torch.cat((hidden_input, conv6_out), 1))\n",
        "\n",
        "        up4_out = self.up4(torch.cat((up5_out, conv5_out), 1))\n",
        "        up3_out = self.up3(torch.cat((up4_out, conv4_out), 1))\n",
        "        up2_out = self.up2(torch.cat((up3_out, conv3_out), 1))\n",
        "        up1_out = self.up1(torch.cat((up2_out, conv2_out), 1))\n",
        "        up0_out = self.up0(torch.cat((up1_out, conv1_out), 1))\n",
        "        out = self.end(torch.cat((up0_out, conv0_out), 1))\n",
        "        out = F.sigmoid(out)\n",
        "        return out, mid\n",
        "\n",
        "def conv_stage(dim_in, dim_out):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(dim_in, dim_out, 4, 2, 1,bias=False),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.BatchNorm2d(dim_out)\n",
        "    )\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(3, Param.cnn_channel, 3, 1, 1,bias=False)\n",
        "        self.conv1 = conv_stage(Param.cnn_channel, Param.cnn_channel * 2)\n",
        "        self.conv2 = conv_stage(Param.cnn_channel * 2, Param.cnn_channel * 4)\n",
        "        self.conv3 = nn.Conv2d(Param.cnn_channel * 4, 1, 4, 1, 1)\n",
        "        self.bn0 = nn.BatchNorm2d(Param.cnn_channel)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "                # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                # m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                nn.init.kaiming_normal(m.weight.data, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, data_in):  # map   channel\n",
        "        conv0_out = self.conv0(data_in)  # 128   64\n",
        "        conv0_out = self.bn0(conv0_out)\n",
        "        conv1_out = self.conv1(conv0_out)  # 64    128\n",
        "        conv2_out = self.conv2(conv1_out)  # 32    256\n",
        "        out = self.conv3(conv2_out)  # 31    1\n",
        "        out = F.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "class ImageNetData(object):\n",
        "    def __init__(self, csv_file, trans=None):\n",
        "        self.lines = pd.read_csv(csv_file)\n",
        "        self.trans = trans\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lines)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # print(self.lines)\n",
        "        image_pos = self.lines.loc[idx, 0]\n",
        "        image = io.imread(image_pos)\n",
        "        image = image.astype(np.float)\n",
        "        h,w = image.shape[:2]\n",
        "        if(h<w):\n",
        "            factor = h/350.0\n",
        "            w = w/factor\n",
        "            h = 350\n",
        "        else:\n",
        "            factor = w/350.0\n",
        "            h = h/factor\n",
        "            w = 350\n",
        "        image = transform.resize(image, (int(h), int(w), 3))\n",
        "        image_id = self.lines.loc[idx, '0']\n",
        "        sample = {'image': image, 'id': image_id}\n",
        "        if self.trans is not None:\n",
        "            sample = self.trans(sample)\n",
        "        return sample\n",
        "\n",
        "class ParisData(object):\n",
        "    def __init__(self, csv_file, trans=None):\n",
        "        self.lines = pd.read_csv(csv_file)\n",
        "        self.trans = trans\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lines)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # print(self.lines)\n",
        "        image_pos = self.lines.loc[idx, '0']\n",
        "        image = io.imread(image_pos)\n",
        "        image = image.astype(np.float)\n",
        "        h,w = image.shape[:2]\n",
        "        if(h<w):\n",
        "            factor = h/350.0\n",
        "            w = w/factor\n",
        "            h = 350\n",
        "        else:\n",
        "            factor = w/350.0\n",
        "            h = h/factor\n",
        "            w = 350\n",
        "        image = transform.resize(image, (int(h), int(w), 3))\n",
        "        image_id = self.lines.loc[idx, '1']\n",
        "        sample = {'image': image, 'id': image_id}\n",
        "        if self.trans is not None:\n",
        "            sample = self.trans(sample)\n",
        "        return sample\n",
        "\n",
        "\n",
        "class RandCrop(object):\n",
        "    def __call__(self, sample):\n",
        "        image = sample['image']\n",
        "        image_id = sample['id']\n",
        "        h, w = image.shape[:2]\n",
        "        sx = random.randint(0, h - Param.image_size)\n",
        "        sy = random.randint(0, w - Param.image_size)\n",
        "        image = image[sx:(sx + Param.image_size), sy:(sy + Param.image_size)]\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        if(random.randint(0,1)):\n",
        "            image = image[:,:,::-1]\n",
        "        image /= 255.0\n",
        "        image_trans = np.array(image)\n",
        "        return {'image': torch.FloatTensor(image_trans), 'id': torch.Tensor([image_id])}\n",
        "\n",
        "\n",
        "def inf_get(train):\n",
        "    while (True):\n",
        "        for x in train:\n",
        "            yield x['image']\n",
        "\n",
        "def destroy(image, crop_size=64):\n",
        "    re = image.clone().cuda()\n",
        "    '''\n",
        "    re[:, :, int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size),\n",
        "    int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size)] = torch.zeros(\n",
        "        Param.batch_size, 3, crop_size, crop_size).cuda()\n",
        "    '''\n",
        "    re[:, 0:1, int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size),\n",
        "    int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size)] = torch.zeros(\n",
        "        Param.batch_size, 1, crop_size, crop_size).fill_(0.45703125).cuda()\n",
        "    re[:, 1:2, int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size),\n",
        "    int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size)] = torch.zeros(\n",
        "        Param.batch_size, 1, crop_size, crop_size).fill_(0.40625).cuda()\n",
        "    re[:, 2:3, int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size),\n",
        "    int((Param.image_size - crop_size) / 2):int((Param.image_size - crop_size) / 2 + crop_size)] = torch.zeros(\n",
        "        Param.batch_size, 1, crop_size, crop_size).fill_(0.48046875).cuda()\n",
        "\n",
        "    return re\n",
        "\n",
        "\n",
        "class Net_G(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_G, self).__init__()\n",
        "        self.unet_1 = Unet(3, Param.unet_channel * 8)\n",
        "        self.unet_2 = Unet(6, Param.unet_channel * 8 * 3)\n",
        "        self.unet_3 = Unet(6, Param.unet_channel * 8 * 3)\n",
        "        self.unet_4 = Unet(6, Param.unet_channel * 8 * 3)\n",
        "        self.rnn = nn.LSTMCell(Param.unet_channel * 8, Param.unet_channel * 8 * 2)\n",
        "\n",
        "    def forward(self, data_1, data_2, data_3, data_4, h0, c0):\n",
        "        #print(data_1.size())\n",
        "        unet_out_1, unet_mid_1 = self.unet_1(data_1)\n",
        "        h1, c1 = self.rnn(unet_mid_1.view(Param.batch_size, -1), (h0, c0))\n",
        "        unet_out_2, unet_mid_2 = self.unet_2(torch.cat((data_1, unet_out_1), 1), h1)\n",
        "        h2, c2 = self.rnn(unet_mid_2.view(Param.batch_size, -1), (h1, c1))\n",
        "        unet_out_3, unet_mid_3 = self.unet_3(torch.cat((data_1, unet_out_2), 1), h2)\n",
        "        h3, c3 = self.rnn(unet_mid_3.view(Param.batch_size, -1), (h2, c2))\n",
        "        unet_out_4, unet_mid_4 = self.unet_4(torch.cat((data_1, unet_out_3), 1), h3)\n",
        "        return unet_out_1, unet_out_2, unet_out_3, unet_out_4\n",
        "\n",
        "\n",
        "class Net_D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_D, self).__init__()\n",
        "        self.cnn1 = CNN()\n",
        "        self.cnn2 = CNN()\n",
        "        self.cnn3 = CNN()\n",
        "        self.cnn4 = CNN()\n",
        "\n",
        "    def forward(self, data_48, data_32, data_16, data_0):\n",
        "        out1 = self.cnn1(data_48)\n",
        "        out2 = self.cnn2(data_32)\n",
        "        out3 = self.cnn3(data_16)\n",
        "        out4 = self.cnn4(data_0)\n",
        "        return out1, out2, out3, out4\n",
        "\n",
        "\n",
        "def save_image_plus(x, save_path):\n",
        "    x = (255.99 * x).astype('uint8')\n",
        "    x = x.transpose(0, 1, 3, 4, 2)\n",
        "    nh, nw = x.shape[:2]\n",
        "    h = x.shape[2]\n",
        "    w = x.shape[3]\n",
        "    img = np.zeros((h * nh, w * nw, 3))\n",
        "    for i in range(nh):\n",
        "        for j in range(nw):\n",
        "            img[i * h:i * h + h, j * w:j * w + w] = x[i][j]\n",
        "    imageio.imwrite(save_path, img)\n",
        "    # imsave(save_path, img)\n",
        "\n",
        "def cal_tv(image):\n",
        "    temp = image.clone()\n",
        "    temp[:,:,:Param.image_size-1,:] = image[:,:,1:,:]\n",
        "    re = ((image-temp)**2).mean()\n",
        "    temp = image.clone()\n",
        "    temp[:,:,:,:Param.image_size-1] = image[:,:,:,1:]\n",
        "    re += ((image-temp)**2).mean()\n",
        "    return re\n",
        "\n",
        "def ssim_fn(y_true, y_pred):\n",
        "    ssim_val = 0\n",
        "    for i in range(y_true.shape[0]):\n",
        "        true_img = y_true[i, :, :, :]\n",
        "        pred_img = y_pred[i, :, :, :]\n",
        "        true_img = cv2.cvtColor(true_img.permute(1,2,0).detach().cpu().numpy(), cv2.COLOR_RGB2GRAY)\n",
        "        pred_img = cv2.cvtColor(pred_img.permute(1,2,0).detach().cpu().numpy(), cv2.COLOR_RGB2GRAY)\n",
        "        ssim_val += ssim(true_img, pred_img, data_range=255)\n",
        "    return ssim_val / y_true.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one = torch.FloatTensor([1.0]).cuda() //deprecateed\n",
        "scaler = amp.GradScaler()\n",
        "one = torch.tensor(1.0, dtype=torch.float).cuda()\n",
        "mone = torch.tensor(-1.0, dtype=torch.float).cuda()\n",
        "# mone = torch.FloatTensor([-1.0]).cuda()\n",
        "ones_31 = torch.zeros(Param.batch_size, 1, 31, 31).fill_(1.0).type(torch.FloatTensor).cuda()\n",
        "mones_31 = torch.zeros(Param.batch_size, 1, 31, 31).fill_(-1.0).type(torch.FloatTensor).cuda()\n",
        "zeros_31 = torch.zeros(Param.batch_size, 1, 31, 31).type(torch.FloatTensor).cuda()\n",
        "\n",
        "mask = torch.ones(Param.batch_size, 3, 128, 128)\n",
        "mask[:, :, 32:32 + 64, 32:32 + 64] = torch.zeros(Param.batch_size, 3, 64, 64)\n",
        "mask = Variable(mask.type(torch.FloatTensor).cuda(), requires_grad=False)\n",
        "\n",
        "h0 = torch.zeros(Param.batch_size, Param.unet_channel * 8 * 2).cuda()\n",
        "c0 = torch.zeros(Param.batch_size, Param.unet_channel * 8 * 2).cuda()\n",
        "\n",
        "netG = Net_G().cuda()\n",
        "netD = Net_D().cuda()\n",
        "\n",
        "#netG.load_state_dict(torch.load('/data/haoran/unet-gan/gan_lstm_4/netG_59999.pickle'))\n",
        "#netD.load_state_dict(torch.load('/data/haoran/unet-gan/gan_lstm_4/netD_59999.pickle'))\n",
        "#netG = nn.DataParallel(netG, device_ids=[0, 1])\n",
        "#netD = nn.DataParallel(netD, device_ids=[0, 1])\n",
        "\n",
        "opt_G = optim.Adam(netG.parameters(), lr=Param.G_learning_rate, betas = (0.5,0.999), weight_decay=Param.weight_decay)\n",
        "opt_D = optim.Adam(netD.parameters(), lr=Param.D_learning_rate, betas = (0.5,0.999), weight_decay=Param.weight_decay)\n",
        "\n",
        "#trainset = ParisData('paris.csv', RandCrop())\n",
        "trainset = ParisData('/content/Progressive-Generative-Networks/gan_lstm.csv', RandCrop())\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=Param.batch_size, shuffle=True, num_workers=2,\n",
        "                                            drop_last=True)\n",
        "train_data = inf_get(train_loader)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8v8EZWnpC33",
        "outputId": "89b84d57-f72c-4dcf-cb4b-7ff5564eaea8"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-89-6d3113006b5e>:90: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data, mode='fan_out')\n",
            "<ipython-input-89-6d3113006b5e>:145: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data, mode='fan_out')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_start = 0\n",
        "maxepoch = 10\n",
        "bce_loss = nn.BCELoss()"
      ],
      "metadata": {
        "id": "qSoWOhP1plBi"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import time"
      ],
      "metadata": {
        "id": "0U0DlvcOqrSr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yIdDFrqT5-zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity\n"
      ],
      "metadata": {
        "id": "XuOPTdAOxIHj"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_memory_bandwidth(data_size_bytes, time_sec):\n",
        "    return data_size_bytes / time_sec / 1e9"
      ],
      "metadata": {
        "id": "UzcdaXwwSZL7"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_flops(model, input_shape):\n",
        "    inputs = torch.randn(*input_shape)\n",
        "    flops, _ = torch.autograd.profiler.profile(lambda: model(inputs), verbose=False)\n",
        "    return flops / 1e9"
      ],
      "metadata": {
        "id": "ezUJ8oe8SbJO"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "EJMXO28G9CEO"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train_runner(epoch, maxepoch, bce_loss,val):\n",
        "    # run the model with profiling\n",
        "    \n",
        "    while (epoch < maxepoch):\n",
        "        start_time = time.time()\n",
        "        # step D\n",
        "        for p in netD.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "        real_data = next(train_data)\n",
        "        # print(real_data)\n",
        "        real_data = real_data.cuda()\n",
        "        real_data_64 = destroy(real_data, 64)\n",
        "        real_data_48 = destroy(real_data, 48)\n",
        "        real_data_32 = destroy(real_data, 32)\n",
        "        real_data_16 = destroy(real_data, 16)\n",
        "\n",
        "        real_data_64 = Variable(real_data_64)\n",
        "        real_data_48 = Variable(real_data_48)\n",
        "        real_data_32 = Variable(real_data_32)\n",
        "        real_data_16 = Variable(real_data_16)\n",
        "        real_data_0 = Variable(real_data)\n",
        "\n",
        "        netD.zero_grad()\n",
        "        with amp.autocast():\n",
        "            p_real_48, p_real_32, p_real_16, p_real_0 = netD(real_data_48, real_data_32, real_data_16, real_data_0)\n",
        "            target = Variable(ones_31)\n",
        "\n",
        "            #print(p_real_48.size())\n",
        "            real_loss_48 = bce_loss(p_real_48, target)\n",
        "            real_loss_32 = bce_loss(p_real_32, target)\n",
        "            real_loss_16 = bce_loss(p_real_16, target)\n",
        "            real_loss_0 = bce_loss(p_real_0, target)\n",
        "\n",
        "            fake_data_48, fake_data_32, fake_data_16, fake_data_0 = netG(real_data_64, real_data_48, real_data_32,\n",
        "                                                                            real_data_16, Variable(h0), Variable(c0))\n",
        "\n",
        "            p_fake_48, p_fake_32, p_fake_16, p_fake_0 = netD(Variable(fake_data_48.data), Variable(fake_data_32.data), Variable(fake_data_16.data), Variable(fake_data_0.data))\n",
        "            target = Variable(zeros_31)\n",
        "            fake_loss_48 = bce_loss(p_fake_48, target)\n",
        "            fake_loss_32 = bce_loss(p_fake_32, target)\n",
        "            fake_loss_16 = bce_loss(p_fake_16, target)\n",
        "            fake_loss_0 = bce_loss(p_fake_0, target)\n",
        "\n",
        "            gan_loss = real_loss_48 + real_loss_32 + real_loss_16 + real_loss_0 + fake_loss_48 + fake_loss_32 + fake_loss_16 + fake_loss_0\n",
        "            gan_loss = gan_loss\n",
        "\n",
        "\n",
        "            l1_loss = ((fake_data_48 - real_data_48).abs()).mean() + ((fake_data_32 - real_data_32).abs()).mean() + ((\n",
        "                fake_data_16 - real_data_16).abs()).mean() + ((fake_data_0 - real_data_0).abs()).mean()\n",
        "\n",
        "            tv_loss = cal_tv(fake_data_48) + cal_tv(fake_data_32) + cal_tv(fake_data_16) + cal_tv(fake_data_0)\n",
        "            tv_loss = tv_loss * Param.tv_weight\n",
        "        #gan_loss.backward()\n",
        "        scaler.scale(gan_loss).backward(retain_graph=True)\n",
        "        scaler.step(opt_D)\n",
        "        scaler.update()        \n",
        "\n",
        "        # D_cost = fake_loss_48.data + fake_loss_32.data + fake_loss_16.data + fake_loss_0.data\n",
        "        # D_cost += real_loss_48.data + real_loss_32.data + real_loss_16.data + real_loss_0.data\n",
        "\n",
        "        #opt_D.step()\n",
        "\n",
        "        ##################\n",
        "        ## step G ########\n",
        "        ##################\n",
        "        for p in netD.parameters():\n",
        "            p.requires_grad = False\n",
        "        netG.zero_grad()\n",
        "\n",
        "\n",
        "        with amp.autocast():\n",
        "            p_fake_48, p_fake_32, p_fake_16, p_fake_0 = netD(fake_data_48, fake_data_32, fake_data_16, fake_data_0)\n",
        "            #target = Variable(ones_31)\n",
        "            target = Variable(zeros_31)\n",
        "            fake_loss_48 = bce_loss(p_fake_48, target)\n",
        "            fake_loss_32 = bce_loss(p_fake_32, target)\n",
        "            fake_loss_16 = bce_loss(p_fake_16, target)\n",
        "            fake_loss_0 = bce_loss(p_fake_0, target)\n",
        "\n",
        "            gan_loss = fake_loss_48 + fake_loss_32 + fake_loss_16 + fake_loss_0\n",
        "            gan_loss = - gan_loss * Param.gan_weight\n",
        "\n",
        "\n",
        "        scaler.scale(gan_loss).backward(retain_graph=True)\n",
        "        scaler.scale(l1_loss).backward(retain_graph=True)\n",
        "        scaler.scale(tv_loss).backward(retain_graph=True)\n",
        "        scaler.step(opt_G)\n",
        "        scaler.update()   \n",
        "        # gan_loss.backward(retain_graph=True)\n",
        "        # l1_loss.backward(one, retain_graph=True)\n",
        "        # tv_loss.backward(one, retain_graph=True)\n",
        "\n",
        "        # G_cost = fake_loss_48.data + fake_loss_32.data + fake_loss_16.data + fake_loss_0.data\n",
        "        # G_cost += l1_loss.data\n",
        "        # opt_G.step()\n",
        "        print('Epoch:', epoch, 'L1 Loss:', l1_loss.data)\n",
        "\n",
        "        os.chdir(Param.out_path)\n",
        "        # print('Train D Cost:', D_cost)\n",
        "        print('Time Elapsed:', time.time() - start_time)\n",
        "        # print('Train G Cost:', G_cost)\n",
        "        print('Train L1 Loss:', l1_loss.data.cpu().numpy())\n",
        "\n",
        "        times.append(time.time() - start_time)\n",
        "        \n",
        "\n",
        "        power_usage = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # convert to watts\n",
        "        utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
        "        gpu_utilization = utilization.gpu\n",
        "        temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)\n",
        "        power_list.append(power_usage)\n",
        "        gpu_list.append(gpu_utilization)\n",
        "        #fan_list.append(fan_speed)\n",
        "        temp_list.append(temperature)\n",
        "        loss_list.append(l1_loss.data.cpu().numpy())\n",
        "        mse = torch.mean((fake_data_0.data - real_data_0.data) ** 2)\n",
        "        print('mse: '+str(mse))\n",
        "        # psnr = 20 * torch.log10(1 / torch.sqrt(mse))\n",
        "        # psnr_list.append(psnr.item())\n",
        "        # ssim=ssim_fn(fake_data_0,real_data_0)\n",
        "        # ssim_list.append(ssim)\n",
        "\n",
        "        if epoch % 100 == 99:\n",
        "            out_image = torch.cat(\n",
        "                (\n",
        "                    fake_data_48.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    fake_data_32.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    fake_data_16.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    fake_data_0.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    real_data_64.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    real_data_48.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    real_data_32.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    real_data_16.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size),\n",
        "                    real_data_0.data.view(Param.batch_size, 1, 3, Param.image_size, Param.image_size)\n",
        "                ),\n",
        "                1\n",
        "            )\n",
        "            save_image_plus(out_image.cpu().numpy(), Param.out_path + 'train_image_{}.jpg'.format(epoch))\n",
        "\n",
        "        if epoch % 100 == 99:\n",
        "            torch.save(netD.state_dict(),Param.out_path+ 'netD_{}.pickle'.format(epoch))\n",
        "            torch.save(netG.state_dict(),Param.out_path+ 'netG_{}.pickle'.format(epoch))\n",
        "        diff=l1_loss.data.cpu().numpy()-val\n",
        "        if(diff<0.0004):\n",
        "          print(\"testing\")\n",
        "          print(diff)\n",
        "          print(l1_loss.data.cpu().numpy())\n",
        "          print(epoch)\n",
        "          break\n",
        "            \n",
        "        epoch += 1\n",
        "          \n",
        "    \n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/output_V100_mp/V100_lists.pkl','rb') as f:\n",
        "  lists=pickle.load(f)\n",
        "val=lists[7][-1]"
      ],
      "metadata": {
        "id": "FaErYAfWf-Tn"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1z0MpjtF8nF",
        "outputId": "07202177-ac27-4bfd-abaf-37a45575aec2"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.31375197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_runner(epoch_start, 100, torch.nn.functional.binary_cross_entropy_with_logits)\n",
        "power_list=[]\n",
        "temp_list=[]\n",
        "gpu_list=[]\n",
        "fan_list=[]\n",
        "psnr_list=[]\n",
        "ssim_list=[]\n",
        "times = []\n",
        "loss_list=[]\n",
        "train_runner(epoch_start, 200, torch.nn.functional.binary_cross_entropy_with_logits,val)\n",
        "print('warmup')\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True, profile_memory=True) as prof:\n",
        "    train_runner(epoch_start, 1, torch.nn.functional.binary_cross_entropy_with_logits,val)\n",
        "#print(f\"Epoch {0}: {prof.key_averages().memory_bandwidth}\")\n",
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
        "  #analyze the profiling results\n",
        "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTlKpxjKpiSd",
        "outputId": "773c4b28-d5eb-4915-baaf-9bf81e936c26"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 L1 Loss: tensor(0.3980, device='cuda:0')\n",
            "Time Elapsed: 0.22330594062805176\n",
            "Train L1 Loss: 0.3979774\n",
            "mse: tensor(0.0208, device='cuda:0')\n",
            "Epoch: 1 L1 Loss: tensor(0.3134, device='cuda:0')\n",
            "Time Elapsed: 0.24210309982299805\n",
            "Train L1 Loss: 0.31340593\n",
            "mse: tensor(0.0131, device='cuda:0')\n",
            "testing\n",
            "-0.00034603477\n",
            "0.31340593\n",
            "1\n",
            "warmup\n",
            "Epoch: 0 L1 Loss: tensor(0.3436, device='cuda:0')\n",
            "Time Elapsed: 0.32890963554382324\n",
            "Train L1 Loss: 0.34362915\n",
            "mse: tensor(0.0158, device='cuda:0')\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "autograd::engine::evaluate_function: ConvolutionBack...         0.97%       2.745ms        21.17%      59.772ms     262.158us       0.000us         0.00%      82.020ms     359.737us           0 b           0 b       1.28 Gb      -1.42 Gb           228  \n",
            "                                   ConvolutionBackward0         0.74%       2.091ms        20.05%      56.621ms     248.338us       0.000us         0.00%      81.950ms     359.430us           0 b           0 b       2.70 Gb           0 b           228  \n",
            "                             aten::convolution_backward        10.92%      30.849ms        19.31%      54.530ms     239.167us      81.186ms        45.27%      81.950ms     359.430us           0 b           0 b       2.70 Gb       1.61 Gb           228  \n",
            "                                       cudaLaunchKernel        15.15%      42.782ms        15.15%      42.782ms       9.220us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          4640  \n",
            "                                               aten::to         3.16%       8.923ms        12.70%      35.866ms      51.384us       0.000us         0.00%       9.341ms      13.383us         908 b          12 b       2.76 Gb      70.01 Mb           698  \n",
            "autograd::engine::evaluate_function: CudnnBatchNormB...         0.86%       2.438ms        11.86%      33.484ms     164.137us       0.000us         0.00%      16.034ms      78.598us           0 b           0 b     190.25 Mb    -874.91 Mb           204  \n",
            "                                CudnnBatchNormBackward0         0.85%       2.413ms        10.84%      30.614ms     150.069us       0.000us         0.00%      15.962ms      78.245us           0 b           0 b       1.04 Gb    -211.31 Mb           204  \n",
            "                                         aten::_to_copy         3.70%      10.440ms         9.84%      27.793ms      42.497us       0.000us         0.00%       9.598ms      14.676us         908 b          32 b       2.76 Gb           0 b           654  \n",
            "                                           aten::conv2d         0.39%       1.107ms         9.22%      26.031ms     179.524us       0.000us         0.00%      29.860ms     205.931us           0 b           0 b       1.62 Gb     -10.00 Kb           145  \n",
            "                               Optimizer.step#Adam.step         2.64%       7.460ms         7.19%      20.303ms      10.152ms       0.000us         0.00%      20.460ms      10.230ms           0 b           0 b           0 b      -1.50 Gb             2  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 282.403ms\n",
            "Self CUDA time total: 179.330ms\n",
            "\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                             aten::convolution_backward        10.92%      30.849ms        19.31%      54.530ms     239.167us      81.186ms        45.27%      81.950ms     359.430us           0 b           0 b       2.70 Gb       1.61 Gb           228  \n",
            "void cudnn::ops::nchwToNhwcKernel<__half, __half, fl...         0.00%       0.000us         0.00%       0.000us       0.000us      20.393ms        11.37%      20.393ms      21.834us           0 b           0 b           0 b           0 b           934  \n",
            "                                aten::cudnn_convolution         2.02%       5.703ms         3.13%       8.852ms     110.650us      15.792ms         8.81%      15.792ms     197.400us           0 b           0 b     862.17 Mb     862.17 Mb            80  \n",
            "                        aten::cudnn_batch_norm_backward         3.34%       9.446ms         6.43%      18.152ms      88.980us      15.119ms         8.43%      15.119ms      74.113us           0 b           0 b       1.04 Gb           0 b           204  \n",
            "void cudnn::bn_bw_1C11_kernel_new<__half, float, flo...         0.00%       0.000us         0.00%       0.000us       0.000us      12.539ms         6.99%      12.539ms     208.983us           0 b           0 b           0 b           0 b            60  \n",
            "                                            aten::copy_         2.89%       8.157ms         6.41%      18.107ms      17.597us      10.994ms         6.13%      10.994ms      10.684us           0 b           0 b           0 b           0 b          1029  \n",
            "void cudnn::ops::nhwcToNchwKernel<__half, __half, fl...         0.00%       0.000us         0.00%       0.000us       0.000us       8.786ms         4.90%       8.786ms      20.869us           0 b           0 b           0 b           0 b           421  \n",
            "                                             aten::add_         3.10%       8.754ms         5.57%      15.729ms      19.019us       8.053ms         4.49%       8.053ms       9.738us         528 b        -380 b           0 b           0 b           827  \n",
            "void xmma_cudnn::implicit_gemm::strided_dgrad_indexe...         0.00%       0.000us         0.00%       0.000us       0.000us       8.024ms         4.47%       8.024ms     200.600us           0 b           0 b           0 b           0 b            40  \n",
            "                                 aten::cudnn_batch_norm         2.01%       5.675ms         3.89%      10.975ms     119.293us       7.325ms         4.08%       7.325ms      79.620us           0 b           0 b     803.25 Mb           0 b            92  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 282.403ms\n",
            "Self CUDA time total: 179.330ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ],
      "metadata": {
        "id": "5Jh0OBchhq7W"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in netG.parameters():\n",
        "    p.requires_grad = True\n",
        "netG.zero_grad()\n",
        "num_params = count_parameters(netG)\n",
        "print(f\"The Generator has {num_params:,} trainable parameters.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K2iLO0hhuls",
        "outputId": "d1f8b5a8-aa5a-4fff-d019-9cbea21b1dd7"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Generator has 199,048,280 trainable parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in netD.parameters():\n",
        "    p.requires_grad = True\n",
        "netG.zero_grad()\n",
        "num_params = count_parameters(netD)\n",
        "print(f\"The Generator has {num_params:,} trainable parameters.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSFjgy0inEdx",
        "outputId": "4d6eccce-8a65-4df9-8fdd-962d93b75ed6"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Generator has 2,648,324 trainable parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dmem_params = sum([param.nelement()*param.element_size() for param in netD.parameters()])\n",
        "dmem_bufs = sum([buf.nelement()*buf.element_size() for buf in netD.buffers()])\n",
        "dmem = dmem_params + dmem_bufs # in bytes\n",
        "print(dmem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rey5esuFnMhq",
        "outputId": "c9a9f0b0-e1c2-435b-b821-50bbdd978707"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10607728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gmem_params = sum([param.nelement()*param.element_size() for param in netG.parameters()])\n",
        "gmem_bufs = sum([buf.nelement()*buf.element_size() for buf in netG.buffers()])\n",
        "gmem = gmem_params + gmem_bufs # in bytes\n",
        "print(gmem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoNwCRgWnRuS",
        "outputId": "b4b5ea59-c02d-4ed8-cd35-7c37a9fd36e3"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "796337024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mem= dmem + gmem\n",
        "print(mem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VXZBD-onX1u",
        "outputId": "2d265d1e-5454-49d3-c9aa-927c6f3abe5e"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "806944752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bandwidth=mem/(times[-1] * 1000000000)\n",
        "print(bandwidth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgEyr5yjnY3Y",
        "outputId": "fde36f0d-cc2f-4353-b0ef-875f6f7e8501"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4413279339081755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flop=2*count_parameters(netG)+count_parameters(netD)\n",
        "print(flop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wrFs0oWnh3K",
        "outputId": "e6930df7-44fc-4214-cd59-25a4265b5026"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400744884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flops=flop/(times[-1] * 1000000000)\n",
        "print(flops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDn-S0G7nnwi",
        "outputId": "6a235813-5a08-4a78-aa16-57f634944b81"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.21241222184687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roofline=[bandwidth,flops]"
      ],
      "metadata": {
        "id": "8SPn9nCfoHkD"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "# Save the lists to a file\n",
        "with open('V100_mp_lists_2.pkl', 'wb') as f:\n",
        "    pickle.dump([power_list, gpu_list, temp_list, psnr_list,ssim_list,times,roofline,loss_list], f)"
      ],
      "metadata": {
        "id": "q6y_RikqoI7o"
      },
      "execution_count": 125,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}