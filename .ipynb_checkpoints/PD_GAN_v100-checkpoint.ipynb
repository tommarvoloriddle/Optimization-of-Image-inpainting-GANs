{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST\n",
    "from torchvision.datasets import CelebA\n",
    "import cv2\n",
    "import time\n",
    "# dataset = CelebA('/scratch/sg7729/hpml_project/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/scratch/sg7729/hpml_project/PD_GAN/')\n",
    "# parser.add_argument('-f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install loguru\n",
    "\n",
    "import sys\n",
    "sys.argv=['']\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.argv\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.parse_args()\n",
    "del sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST\n",
    "import pynvml\n",
    "import pytorch_ssim\n",
    "from skimage.metrics import structural_similarity as ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pynvml.nvmlInit()\n",
    "\n",
    "# Get handle for GPU 0\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "# Get power usage\n",
    "power_usage = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # convert to watts\n",
    "\n",
    "# Get GPU utilization\n",
    "utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "gpu_utilization = utilization.gpu\n",
    "\n",
    "# Get fan speed\n",
    "#fan_speed = pynvml.nvmlDeviceGetFanSpeed(handle)\n",
    "\n",
    "# Get temperature\n",
    "temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_fn(y_true, y_pred):\n",
    "    ssim_val = 0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        true_img = y_true[i, :, :, :]\n",
    "        pred_img = y_pred[i, :, :, :]\n",
    "        true_img = cv2.cvtColor(true_img.permute(1,2,0).detach().cpu().numpy(), cv2.COLOR_RGB2GRAY)\n",
    "        pred_img = cv2.cvtColor(pred_img.permute(1,2,0).detach().cpu().numpy(), cv2.COLOR_RGB2GRAY)\n",
    "        ssim_val += ssim(true_img, pred_img, data_range=255)\n",
    "    return ssim_val / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Config ---------------\n",
      "                basic_dir: /scratch/sg7729/hpml_project/PD-GAN\n",
      "                batchSize: 4                             \n",
      "                    beta1: 0.0                           \n",
      "          checkpoints_dir: checkpoints                   \n",
      "           continue_train: False                         \n",
      "             display_freq: 500                           \n",
      "display_single_pane_ncols: 0                             \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: hinge                         \n",
      "                  gpu_ids: 0                             \n",
      "                  gt_root: /workspace/project-nas-10583/cvpr2020/data/valley\n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "               input_nc_D: 6                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "               lambda_Gan: 1                             \n",
      "                lambda_L1: 1                             \n",
      "                 lambda_P: 10                            \n",
      "                 lambda_S: 10                            \n",
      "                lambda_TV: 0.05                          \n",
      "              lambda_feat: 10.0                          \n",
      "                latent_sh: 4                             \n",
      "                latent_sw: 4                             \n",
      "                  log_dir: logs                          \n",
      "                       lr: 0.001                         \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: lambda                        \n",
      "                mask_root: /workspace/project-nas-10583/cvpr2020/data/testing_mask_dataset\n",
      "                mask_type: random_bbox                   \n",
      "                    model: PDGAN                         \n",
      "                 nThreads: 2                             \n",
      "               n_layers_D: 4                             \n",
      "                     name: PDGAN-Training                \n",
      "                      ndf: 64                            \n",
      "                need_crop: False                         \n",
      "                need_flip: False                         \n",
      "                      ngf: 64                            \n",
      "                    niter: 20                            \n",
      "              niter_decay: 100                           \n",
      "          no_ganFeat_loss: False                         \n",
      "                     norm: instance                      \n",
      "                   norm_D: spectralinstance              \n",
      "                   norm_G: spectral                      \n",
      "                    num_D: 2                             \n",
      "              num_workers: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "    pre_ckpt_PConv_DE_dir:                               \n",
      "    pre_ckpt_PConv_EN_dir:                               \n",
      "               print_freq: 50                            \n",
      "          save_epoch_freq: 2                             \n",
      "         save_latest_freq: 5000                          \n",
      "         train_image_size: 256                           \n",
      "              use_dropout: False                         \n",
      "              which_epoch: 1                             \n",
      "            write_summary: True                          \n",
      "                    z_dim: 256                           \n",
      "----------------- End -------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-05-14 01:50:42.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mDefine the dataset\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flist /scratch/sg7729/hpml_project/celeba/img_align_celeba/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-05-14 01:50:43.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mCreate model\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images 202599\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from config.train_config import TrainConfig\n",
    "from data.dataprocess import Dataset\n",
    "from models.models import create_model\n",
    "from util.util import visualize_grid, mkdir\n",
    "from torch.utils import data\n",
    "from loguru import logger\n",
    "\n",
    "basic_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "import sys\n",
    "\n",
    "sys.path.append(basic_dir)\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = TrainConfig().create_config()\n",
    "    result_save_base_dir = os.path.join(basic_dir, cfg.checkpoints_dir, cfg.name)\n",
    "    logger.add(os.path.join(result_save_base_dir, cfg.log_dir, \"train.log\"))\n",
    "    visual_save_base = os.path.join(result_save_base_dir, \"visuals\")\n",
    "    mkdir(visual_save_base)\n",
    "    if cfg.write_summary:\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "        writer = SummaryWriter(log_dir=os.path.join(result_save_base_dir, cfg.log_dir))\n",
    "    logger.info(\"Define the dataset\")\n",
    "    dataset = Dataset(cfg.gt_root, cfg, mask_file=cfg.mask_root)\n",
    "    iterator_train = data.DataLoader(\n",
    "        dataset, batch_size=cfg.batchSize, shuffle=True, num_workers=cfg.num_workers\n",
    "    )\n",
    "    logger.info(\"Create model\")\n",
    "    model = create_model(cfg)\n",
    "    total_steps = 0\n",
    "    logger.info(\"Start training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epoch):\n",
    "    for epoch in range(cfg.epoch_count, cfg.niter + cfg.niter_decay + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        epoch_iter = 0\n",
    "        total_steps = 0\n",
    "        for gt, mask in iterator_train:\n",
    "            iter_start_time = time.time()\n",
    "            total_steps += cfg.batchSize\n",
    "            epoch_iter += cfg.batchSize\n",
    "            model.set_input(mask, gt)\n",
    "            model.optimize_parameters()\n",
    "\n",
    "            # print loss and time for each iteration\n",
    "            losses = model.get_current_errors()\n",
    "\n",
    "            times.append(time.time() - iter_start_time)\n",
    "\n",
    "            visual_dict = model.get_current_visuals()\n",
    "            power_usage = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # convert to watts\n",
    "            utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "            gpu_utilization = utilization.gpu\n",
    "            temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)\n",
    "            power_list.append(power_usage)\n",
    "            gpu_list.append(gpu_utilization)\n",
    "            #fan_list.append(fan_speed)\n",
    "            temp_list.append(temperature)\n",
    "            mse = torch.mean((visual_dict['input_image'].data - visual_dict['fake_A'].data) ** 2)\n",
    "            psnr = 20 * torch.log10(1 / torch.sqrt(mse))\n",
    "            psnr_list.append(psnr.item())\n",
    "            ssim_val=ssim_fn(visual_dict['input_image'], visual_dict['fake_A'])\n",
    "            ssim_list.append(ssim_val)\n",
    "\n",
    "\n",
    "            loss_info = f\"ExpName: {cfg.name} \\nEpoch: {epoch}, Iter: {epoch_iter}, Time: {time.time() - iter_start_time:.2f} sec \\n\"\n",
    "            for k, v in losses.items():\n",
    "                loss_info = loss_info + f\"{k}: {v.item():.4f}, \"\n",
    "                if cfg.write_summary:\n",
    "                    writer.add_scalar(\"train_loss/\" + k, v, global_step=total_steps)\n",
    "            logger.info(loss_info)\n",
    "            losses_array.append(losses['Perceptual'].item())\n",
    "            # save images every 10 steps\n",
    "            if total_steps % 10 == 0:\n",
    "                visual_dict = model.get_current_visuals()\n",
    "                image_save_path = os.path.join(\n",
    "                    visual_save_base, f\"{total_steps:06}.jpg\"\n",
    "                )\n",
    "                grid_image = visualize_grid(\n",
    "                    visual_dict, image_save_path, return_gird=True\n",
    "                )\n",
    "                writer.add_image(\n",
    "                    \"train_images\",\n",
    "                    (grid_image / 255.0).astype(np.float32).transpose(2, 0, 1),\n",
    "                    total_steps,\n",
    "                )\n",
    "\n",
    "            # save model every epoch\n",
    "            if epoch_iter % len(iterator_train) == 0:\n",
    "                save_info = \"saving the model at the end of epoch {}, iters {}\".format(\n",
    "                    epoch, epoch_iter\n",
    "                )\n",
    "                logger.info(save_info)\n",
    "                model.save_networks(epoch)\n",
    "\n",
    "            if epoch_iter/n_epoch == 1:\n",
    "                return\n",
    "\n",
    "        logger.info(\n",
    "            \"End of epoch {} / {} \\t Time Taken: {} sec\".format(\n",
    "                epoch, cfg.niter + cfg.niter_decay, time.time() - epoch_start_time\n",
    "            )\n",
    "        )\n",
    "        model.update_learning_rate(epoch)\n",
    "        if epoch_iter/n_epoch == 1:\n",
    "            return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "power_list=[]\n",
    "temp_list=[]\n",
    "gpu_list=[]\n",
    "fan_list=[]\n",
    "psnr_list=[]\n",
    "ssim_list=[]\n",
    "times = []\n",
    "losses_array = []\n",
    "n_epoch = 100\n",
    "\n",
    "train(n_epoch * 8)\n",
    "print('warmup')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True, profile_memory=True) as prof:\n",
    "    train(1 * 8)\n",
    "#print(f\"Epoch {0}: {prof.key_averages().memory_bandwidth}\")\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "  #analyze the profiling results\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN = model.netEN\n",
    "DE = model.netDE\n",
    "PD = model.netPDGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = count_parameters(EN)\n",
    "\n",
    "print(f\"The Encoeder has {num_params:,} trainable parameters.\")\n",
    "\n",
    "num_params = count_parameters(DE)\n",
    "\n",
    "print(f\"The Decoder has {num_params:,} trainable parameters.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = count_parameters(PD)\n",
    "\n",
    "print(f\"The PDGAN has {num_params:,} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot  as plt\n",
    "# create a figure with 4 subplots\n",
    "fig, axs = plt.subplots(5, 1, figsize=(10, 12))\n",
    "\n",
    "# plot power usage\n",
    "axs[0].plot(power_list)\n",
    "axs[0].set_title('Power Usage')\n",
    "axs[0].set_ylabel('Power (W)')\n",
    "axs[0].set_xlabel('Iteration')\n",
    "\n",
    "# plot GPU utilization\n",
    "axs[1].plot(gpu_list)\n",
    "axs[1].set_title('GPU Utilization')\n",
    "axs[1].set_ylabel('Utilization (%)')\n",
    "axs[1].set_xlabel('Iteration')\n",
    "\n",
    "# plot temperature\n",
    "axs[2].plot(temp_list)\n",
    "axs[2].set_title('GPU Temperature')\n",
    "axs[2].set_ylabel('Temperature (C)')\n",
    "\n",
    "# plot PSNR\n",
    "axs[3].plot(psnr_list)\n",
    "axs[3].set_title('PSNR')\n",
    "axs[3].set_xlabel('Iteration')\n",
    "axs[3].set_ylabel('PSNR (dB)')\n",
    "\n",
    "# plot SSIM\n",
    "axs[4].plot(losses_array)\n",
    "axs[4].set_title('Loss')\n",
    "axs[4].set_xlabel('Iteration')\n",
    "axs[4].set_ylabel('loss')\n",
    "\n",
    "# set the layout of the subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmem_params = sum([param.nelement()*param.element_size() for param in EN.parameters()])\n",
    "dmem_bufs = sum([buf.nelement()*buf.element_size() for buf in EN.buffers()])\n",
    "dmem = dmem_params + dmem_bufs # in bytes\n",
    "print(dmem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmem_params = sum([param.nelement()*param.element_size() for param in DE.parameters()])\n",
    "gmem_bufs = sum([buf.nelement()*buf.element_size() for buf in DE.buffers()])\n",
    "gmem = gmem_params + gmem_bufs # in bytes\n",
    "print(gmem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmem_params = sum([param.nelement()*param.element_size() for param in DE.parameters()])\n",
    "pmem_bufs = sum([buf.nelement()*buf.element_size() for buf in DE.buffers()])\n",
    "pmem = pmem_params + gmem_bufs # in bytes\n",
    "print(pmem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = dmem + gmem + pmem\n",
    "print(mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth=mem/(times[-1] * 1000000000)\n",
    "print(bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flop=2*count_parameters(EN)+count_parameters(DE)+count_parameters(PD)\n",
    "print(flop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flops=flop/(times[-1] * 1000000000)\n",
    "print(flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roofline=[bandwidth,flops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Save the lists to a file\n",
    "with open('v100lists_PDGAN_loss.pkl', 'wb') as f:\n",
    "    pickle.dump([power_list, gpu_list, temp_list, psnr_list, ssim_list, times, roofline, losses_array], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
